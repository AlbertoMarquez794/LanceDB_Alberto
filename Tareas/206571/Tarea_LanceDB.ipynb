{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dXVF2G3AQ_HX"
   },
   "source": [
    "# **TAREA LanceDB**\n",
    "- Considera usar ANN para cada búsqueda o filtro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAWMZKlqOeHf"
   },
   "source": [
    "**Task 1: Consulta avanzada con proyección y filtro**\n",
    "\n",
    "Instrucciones:\n",
    "1. Genera un vector aleatorio con la misma dirección que los embeddings que están en la tabla mis_vectores\n",
    "2. Realiza una búsqueda en la tabla para encontrar los 5 elementos más cercanos\n",
    "3. Proyecta los resultados para mostrar solo las columnas item y _distance\n",
    "4. Excluye de los resultado los elementos cuyo nombre sea 'item 500'\n",
    "\n",
    "Pregunta: ¿Cuáles son los cinco elementos más cercanos que cumplen con los criterios y cuál es la distancia de cada uno?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lancedb\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "uri = \"/Users/juancasasmartinez/Documents/ITAM/Fuentes/proyectos_finales/proyecto_lance/notebooks/data/ANN\"\n",
    "db = lancedb.connect(uri)\n",
    "table = db.open_table(\"mis_vectores\")\n",
    "\n",
    "len(table.to_pandas().iloc[0]['vector'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Los 5 elementos más cercanos y sus distancias son:\n",
      "Item 91754, Distancia: 414.7281\n",
      "Item 63165, Distancia: 415.0065\n",
      "Item 119503, Distancia: 415.8102\n",
      "Item 188292, Distancia: 417.5602\n",
      "Item 163104, Distancia: 418.6127\n"
     ]
    }
   ],
   "source": [
    "# 1.\n",
    "query_vector = np.random.randn(1536)\n",
    "query_vector = query_vector / np.linalg.norm(query_vector)  \n",
    "\n",
    "# 2. 3. 4.\n",
    "results = table.search(query_vector).where(\"item != 'item 500'\").limit(5).to_pandas()[['item', '_distance']]\n",
    "\n",
    "\n",
    "print(\"\\nLos 5 elementos más cercanos y sus distancias son:\")\n",
    "for _, row in results.iterrows():\n",
    "    print(f\"{row['item'].capitalize()}, Distancia: {row['_distance']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iGMzKnyOPPOF"
   },
   "source": [
    "**Task 2: Creación de tablas**\n",
    "\n",
    "Instrucciones:\n",
    "1. Define un nuevo esquema para una tabla vacía con las siguientes columnas:\n",
    "*   vector (vector de 4 dimensiones)\n",
    "*   nombre\n",
    "*   categoria\n",
    "2. Crea una tabla vacía llamada nueva_tabla usando el esquema\n",
    "3. Inserta 5 registros en la tabla\n",
    "4. Muestra el contenido de la tabla\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "ekQhX-IrRMto"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-03T00:37:14Z WARN  lance::dataset] No existing dataset at /Users/juancasasmartinez/Documents/ITAM/Fuentes/proyectos_finales/proyecto_lance/notebooks/data/ANN/nueva_tabla.lance, it will be created\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vector</th>\n",
       "      <th>nombre</th>\n",
       "      <th>categoria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.8146985, 0.42480254, 0.67282945, 0.008298699]</td>\n",
       "      <td>imagen_1.jpg</td>\n",
       "      <td>retrato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.61230177, 0.9474902, 0.93997717, 0.6534582]</td>\n",
       "      <td>imagen_2.jpg</td>\n",
       "      <td>naturaleza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.91663516, 0.84984857, 0.5960665, 0.78153455]</td>\n",
       "      <td>imagen_3.jpg</td>\n",
       "      <td>naturaleza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.23287244, 0.16927856, 0.2698172, 0.6164252]</td>\n",
       "      <td>imagen_4.jpg</td>\n",
       "      <td>retrato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.87131745, 0.5638662, 0.15084295, 0.010460604]</td>\n",
       "      <td>imagen_5.jpg</td>\n",
       "      <td>paisaje</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             vector        nombre   categoria\n",
       "0  [0.8146985, 0.42480254, 0.67282945, 0.008298699]  imagen_1.jpg     retrato\n",
       "1    [0.61230177, 0.9474902, 0.93997717, 0.6534582]  imagen_2.jpg  naturaleza\n",
       "2   [0.91663516, 0.84984857, 0.5960665, 0.78153455]  imagen_3.jpg  naturaleza\n",
       "3    [0.23287244, 0.16927856, 0.2698172, 0.6164252]  imagen_4.jpg     retrato\n",
       "4  [0.87131745, 0.5638662, 0.15084295, 0.010460604]  imagen_5.jpg     paisaje"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "data = []\n",
    "\n",
    "for i in range(5):\n",
    "    vector = np.random.rand(4).astype('float32')\n",
    "    \n",
    "    data.append({\n",
    "        'vector': vector.tolist(),\n",
    "        'nombre': f'imagen_{i+1}.jpg',\n",
    "        'categoria': np.random.choice(['paisaje', 'retrato', 'naturaleza'])\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# 1. \n",
    "schema = pa.schema([\n",
    "    (\"vector\", pa.list_(pa.float32(), list_size=4)),\n",
    "    (\"nombre\", pa.string()),\n",
    "    (\"categoria\", pa.string())\n",
    "])\n",
    "\n",
    "# 2. \n",
    "table = pa.Table.from_pandas(df, schema=schema)\n",
    "nueva_tabla = db.create_table(\"nueva_tabla\", data=table, mode=\"overwrite\")\n",
    "\n",
    "nueva_tabla.to_pandas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PMTgGIZbP4V6"
   },
   "source": [
    "**Task 3: Actualización de vectores y filtrado**\n",
    "\n",
    "Instrucciones:\n",
    "1. Crea una tabla utilizando un DataFrame de Pandas con las siguientes columnas:\n",
    "- id (Entero).\n",
    "- vector (Lista de tres números flotantes)\n",
    "2. Actualiza el vector de la fila donde id=3 a [10.0, 11.0, 10.0]\n",
    "3. Filtra la tabla para mostrar solo las filas donde al menos un valor del vector sea mayor a 9.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "gKkb7mmgRNWO"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[10.0, 11.0, 10.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[10.0, 11.0, 12.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id              vector\n",
       "2   3  [10.0, 11.0, 10.0]\n",
       "3   4  [10.0, 11.0, 12.0]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. \n",
    "data = {\n",
    "    'id': [1, 2, 3, 4],\n",
    "    'vector': [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0], [10.0, 11.0, 12.0]]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 2. \n",
    "df.at[df[df['id'] == 3].index[0], 'vector'] = [10.0, 11.0, 10.0]\n",
    "\n",
    "# 3. \n",
    "filtered_df = df[df['vector'].apply(lambda x: any(i > 9.0 for i in x))]\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rargPzZFP4nX"
   },
   "source": [
    "**Task 4: Embeddings multimodales y búsqueda combinada**\n",
    "\n",
    "Instrucciones:\n",
    "1. Crea una tabla con datos de texto e imágenes combinados. Incluye las siguientes columnas:\n",
    "- texto (Texto).\n",
    "- imagen (Nombre del archivo de imagen).\n",
    "- embedding_texto (Vector del texto generado con SentenceTransformer).\n",
    "- embedding_imagen (Vector de la imagen generado con ResNet18).\n",
    "2. Realiza una consulta para encontrar los elementos con un texto similar a \"La tecnología avanza rápido\" y una imagen visualmente similar a un color predominantemente azul.\n",
    "3. Muestra los resultados combinados ordenados por la menor distancia promedio entre ambos embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juancasasmartinez/Library/Python/3.9/lib/python/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/Users/juancasasmartinez/Library/Python/3.9/lib/python/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/juancasasmartinez/Library/Python/3.9/lib/python/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "from PIL import Image\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "data = [\n",
    "    {\"id\": 1, \"texto\": \"La roca de joven\", \"imagen\": \"imagen_1.jpg\"},\n",
    "    {\"id\": 2, \"texto\": \"El perro con lentes\", \"imagen\": \"imagen_2.jpg\"},\n",
    "    {\"id\": 3, \"texto\": \"Señor bean\", \"imagen\": \"imagen_3.jpg\"}\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "text_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "image_model = resnet18(pretrained=True)\n",
    "image_model.fc = torch.nn.Identity()\n",
    "image_model.eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "embeddings_texto = []\n",
    "embeddings_imagen = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    embeddings_texto.append(text_model.encode(row[\"texto\"]).tolist())\n",
    "    image = Image.open(f'/Users/juancasasmartinez/Documents/ITAM/Fuentes/proyectos_finales/proyecto_lance/notebooks/data/images/{row[\"imagen\"]}').convert(\"RGB\")\n",
    "    image_tensor = transform(image).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        embeddings_imagen.append(image_model(image_tensor).squeeze().tolist())\n",
    "\n",
    "df[\"embedding_texto\"] = embeddings_texto\n",
    "df[\"embedding_imagen\"] = embeddings_imagen\n",
    "\n",
    "embedding_size_texto = len(embeddings_texto[0])\n",
    "embedding_size_imagen = len(embeddings_imagen[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-03T01:47:06Z WARN  lance::dataset] No existing dataset at /Users/juancasasmartinez/Documents/ITAM/Fuentes/proyectos_finales/proyecto_lance/notebooks/data/ANN/multimodal_data.lance, it will be created\n"
     ]
    }
   ],
   "source": [
    "schema = pa.schema([\n",
    "    (\"id\", pa.int64()),\n",
    "    (\"texto\", pa.string()),\n",
    "    (\"imagen\", pa.string()),\n",
    "    (\"embedding_texto\", pa.list_(pa.float32(), list_size=embedding_size_texto)),\n",
    "    (\"embedding_imagen\", pa.list_(pa.float32(), list_size=embedding_size_imagen))\n",
    "])\n",
    "\n",
    "table = pa.Table.from_pandas(df, schema=schema)\n",
    "\n",
    "tabla = db.create_table(\"multimodal_data\", schema=schema, mode=\"overwrite\")\n",
    "tabla.add(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 1, Texto: La roca de joven, Imagen: imagen_1.jpg, Distancia Promedio: 0.5710\n",
      "ID: 2, Texto: El perro con lentes, Imagen: imagen_2.jpg, Distancia Promedio: 0.5883\n",
      "ID: 3, Texto: Señor bean, Imagen: imagen_3.jpg, Distancia Promedio: 0.6729\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "\n",
    "consulta_texto = \"La tecnología avanza rápido\"\n",
    "consulta_imagen = \"/Users/juancasasmartinez/Desktop/consulta_azul.jpg\" \n",
    "\n",
    "embedding_consulta_texto = text_model.encode(consulta_texto).tolist()\n",
    "\n",
    "consulta_image = Image.open(consulta_imagen).convert(\"RGB\")\n",
    "consulta_tensor = transform(consulta_image).unsqueeze(0)\n",
    "with torch.no_grad():\n",
    "    embedding_consulta_imagen = image_model(consulta_tensor).squeeze().tolist()\n",
    "\n",
    "resultados_texto = tabla.search(embedding_consulta_texto, \"embedding_texto\").limit(10).to_list()\n",
    "resultados_imagen = tabla.search(embedding_consulta_imagen, \"embedding_imagen\").limit(10).to_list()\n",
    "\n",
    "resultados_combinados = []\n",
    "for texto_row in resultados_texto:\n",
    "    for imagen_row in resultados_imagen:\n",
    "        if texto_row[\"id\"] == imagen_row[\"id\"]:\n",
    "            distancia_texto = cosine(embedding_consulta_texto, texto_row[\"embedding_texto\"])\n",
    "            distancia_imagen = cosine(embedding_consulta_imagen, imagen_row[\"embedding_imagen\"])\n",
    "            promedio_distancia = (distancia_texto + distancia_imagen) / 2\n",
    "            \n",
    "            resultados_combinados.append(\n",
    "                {\n",
    "                    \"id\": texto_row[\"id\"],\n",
    "                    \"texto\": texto_row[\"texto\"],\n",
    "                    \"imagen\": texto_row[\"imagen\"],\n",
    "                    \"distancia_promedio\": promedio_distancia\n",
    "                }\n",
    "            )\n",
    "\n",
    "resultados_combinados.sort(key=lambda x: x[\"distancia_promedio\"])\n",
    "\n",
    "for res in resultados_combinados:\n",
    "    print(f\"ID: {res['id']}, Texto: {res['texto']}, Imagen: {res['imagen']}, Distancia Promedio: {res['distancia_promedio']:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
