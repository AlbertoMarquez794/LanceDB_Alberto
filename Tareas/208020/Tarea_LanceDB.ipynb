{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dXVF2G3AQ_HX"
   },
   "source": [
    "# **TAREA LanceDB**\n",
    "- Considera usar ANN para cada búsqueda o filtro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAWMZKlqOeHf"
   },
   "source": [
    "**Task 1: Consulta avanzada con proyección y filtro**\n",
    "\n",
    "Instrucciones:\n",
    "1. Genera un vector aleatorio con la misma dirección que los embeddings que están en la tabla mis_vectores\n",
    "2. Realiza una búsqueda en la tabla para encontrar los 5 elementos más cercanos\n",
    "3. Proyecta los resultados para mostrar solo las columnas item y _distance\n",
    "4. Excluye de los resultado los elementos cuyo nombre sea 'item 500'\n",
    "\n",
    "Pregunta: ¿Cuáles son los cinco elementos más cercanos que cumplen con los criterios y cuál es la distancia de cada uno?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla 'mis_vectores' creada con 10000 vectores.\n"
     ]
    }
   ],
   "source": [
    "# Cargar librerías necesarias\n",
    "import lancedb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Configurar LanceDB\n",
    "uri = \"data/ANN\"  # Directorio donde se guardará la base de datos\n",
    "db = lancedb.connect(uri)\n",
    "\n",
    "# Crear 10,000 vectores de muestra aleatorios\n",
    "np.random.seed(42)  # Para reproducibilidad\n",
    "data = [\n",
    "    {\"vector\": row, \"item\": f\"item {i}\"}\n",
    "    for i, row in enumerate(np.random.random((10_000, 1536)).astype(\"float32\")) #Le puse solo 10,000 pq mi compu no daba pa más\n",
    "]\n",
    "\n",
    "# Crear tabla en la base de datos\n",
    "tbl = db.create_table(\"mis_vectores\", data=data, mode = \"overwrite\")\n",
    "print(f\"Tabla 'mis_vectores' creada con {len(data)} vectores.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "4ERIHvUROpHn"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-05T17:57:10Z WARN  lance_core::utils::tokio] Number of CPUs is less than or equal to the number of IO core reservations. This is not a supported configuration. using 1 CPU for compute intensive tasks.\n",
      "[2024-12-05T17:57:12Z WARN  lance_core::utils::tokio] Number of CPUs is less than or equal to the number of IO core reservations. This is not a supported configuration. using 1 CPU for compute intensive tasks.\n",
      "[2024-12-05T17:57:12Z WARN  lance_core::utils::tokio] Number of CPUs is less than or equal to the number of IO core reservations. This is not a supported configuration. using 1 CPU for compute intensive tasks.\n",
      "[2024-12-05T17:57:15Z WARN  lance_core::utils::tokio] Number of CPUs is less than or equal to the number of IO core reservations. This is not a supported configuration. using 1 CPU for compute intensive tasks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los 5 elementos más cercanos al vector de consulta son:\n",
      "                                              vector       item   _distance\n",
      "0  [0.37454012, 0.9507143, 0.7319939, 0.5986585, ...     item 0    0.000000\n",
      "1  [0.20024236, 0.60035306, 0.2857333, 0.39349523...  item 1523  230.041855\n",
      "2  [0.47765255, 0.26411608, 0.45712984, 0.9785217...  item 7241  234.380585\n",
      "3  [0.7418995, 0.510742, 0.121364646, 0.2387483, ...  item 3127  236.566757\n",
      "4  [0.4597147, 0.96161556, 0.42014694, 0.99712867...  item 8664  236.600876\n",
      "\n",
      "Resultados proyectados (item y _distance):\n",
      "        item   _distance\n",
      "0     item 0    0.000000\n",
      "1  item 1523  230.041855\n",
      "2  item 7241  234.380585\n",
      "3  item 3127  236.566757\n",
      "4  item 8664  236.600876\n",
      "\n",
      "Pregunta: ¿Cuáles son los cinco elementos más cercanos que cumplen con los criterios y cuál es la distancia de cada uno?\n",
      "\n",
      "Resultados finales tras excluir 'item 500':\n",
      "        item   _distance\n",
      "0     item 0    0.000000\n",
      "1  item 1523  230.041855\n",
      "2  item 7241  234.380585\n",
      "3  item 3127  236.566757\n",
      "4  item 8664  236.600876\n"
     ]
    }
   ],
   "source": [
    "import lancedb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Conectar a la base de datos existente\n",
    "uri = \"data/ANN\"  # Directorio donde se encuentra la base de datos\n",
    "db = lancedb.connect(uri)\n",
    "table = db.open_table(\"mis_vectores\")  # Abrimos la tabla \"mis_vectores\"\n",
    "\n",
    "# Paso 1: Generar un vector aleatorio de la misma dimensión (1536)\n",
    "np.random.seed(42)  # Opcional para reproducibilidad\n",
    "vector_aleatorio = np.random.random(1536).astype(\"float32\")\n",
    "\n",
    "# Paso 2: Realizar la búsqueda ANN para los 5 elementos más cercanos\n",
    "resultados = table.search(vector_aleatorio).limit(5).to_pandas()\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Los 5 elementos más cercanos al vector de consulta son:\")\n",
    "print(resultados)\n",
    "\n",
    "# Paso 3: Proyectar solo las columnas item y _distance\n",
    "resultados_proyectados = resultados[[\"item\", \"_distance\"]]\n",
    "\n",
    "# Mostrar los resultados proyectados\n",
    "print(\"\\nResultados proyectados (item y _distance):\")\n",
    "print(resultados_proyectados)\n",
    "\n",
    "# Paso 4: Excluir elementos cuyo nombre sea \"item 500\"\n",
    "resultados_filtrados = resultados_proyectados[resultados_proyectados[\"item\"] != \"item 500\"]\n",
    "\n",
    "# Seleccionar los 5 primeros resultados tras el filtro\n",
    "resultados_finales = resultados_filtrados.head(5)\n",
    "\n",
    "# Mostrar los resultados finales\n",
    "print(\"\\nPregunta: ¿Cuáles son los cinco elementos más cercanos que cumplen con los criterios y cuál es la distancia de cada uno?\")\n",
    "print(\"\\nResultados finales tras excluir 'item 500':\")\n",
    "print(resultados_finales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iGMzKnyOPPOF"
   },
   "source": [
    "**Task 2: Creación de tablas**\n",
    "\n",
    "Instrucciones:\n",
    "1. Define un nuevo esquema para una tabla vacía con las siguientes columnas:\n",
    "*   vector (vector de 4 dimensiones)\n",
    "*   nombre\n",
    "*   categoria\n",
    "2. Crea una tabla vacía llamada nueva_tabla usando el esquema\n",
    "3. Inserta 5 registros en la tabla\n",
    "4. Muestra el contenido de la tabla\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ekQhX-IrRMto"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-05T17:48:50Z WARN  lance::dataset] No existing dataset at /usr/src/app/notebooks/data/ANN/nueva_tabla.lance, it will be created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla 'nueva_tabla' creada con éxito con el esquema:\n",
      "vector: fixed_size_list<item: float>[4] not null\n",
      "  child 0, item: float\n",
      "nombre: string not null\n",
      "categoria: string not null\n",
      "                 vector      nombre    categoria\n",
      "0  [0.1, 0.2, 0.3, 0.4]      Laptop  Electrónica\n",
      "1  [0.3, 0.1, 0.4, 0.5]   Audífonos  Electrónica\n",
      "2  [0.5, 0.2, 0.1, 0.3]  Smartphone  Electrónica\n",
      "3  [0.6, 0.7, 0.8, 0.9]  Escritorio      Muebles\n",
      "4  [0.9, 0.8, 0.7, 0.6]       Silla      Muebles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-05T17:48:50Z WARN  lance_core::utils::tokio] Number of CPUs is less than or equal to the number of IO core reservations. This is not a supported configuration. using 1 CPU for compute intensive tasks.\n",
      "[2024-12-05T17:48:50Z WARN  lance_core::utils::tokio] Number of CPUs is less than or equal to the number of IO core reservations. This is not a supported configuration. using 1 CPU for compute intensive tasks.\n"
     ]
    }
   ],
   "source": [
    "import lancedb\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import random\n",
    "from lancedb.pydantic import Vector, LanceModel\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# Definir el esquema usando LanceModel\n",
    "class CustomSchema(LanceModel):\n",
    "    vector: Vector(4)  # Vector de 4 dimensiones\n",
    "    nombre: str        # Nombre como cadena\n",
    "    categoria: str     # Categoría como cadena\n",
    "\n",
    "# Conectar o crear la base de datos\n",
    "uri = \"data/ANN\"  # Directorio donde se guardará la base de datos\n",
    "db = lancedb.connect(uri)\n",
    "\n",
    "# Crear la tabla con el esquema definido\n",
    "tabla = db.create_table(\"nueva_tabla\", schema=CustomSchema, mode=\"overwrite\")\n",
    "\n",
    "# Validar el esquema de la tabla\n",
    "print(f\"Tabla '{tabla.name}' creada con éxito con el esquema:\")\n",
    "print(tabla.schema)  # Usar sin paréntesis para mostrar el esquema\n",
    "\n",
    "# Lista de datos para insertar\n",
    "items = [\n",
    "    {\"vector\": [0.1, 0.2, 0.3, 0.4], \"nombre\": \"Laptop\", \"categoria\": \"Electrónica\"},\n",
    "    {\"vector\": [0.3, 0.1, 0.4, 0.5], \"nombre\": \"Audífonos\", \"categoria\": \"Electrónica\"},\n",
    "    {\"vector\": [0.5, 0.2, 0.1, 0.3], \"nombre\": \"Smartphone\", \"categoria\": \"Electrónica\"},\n",
    "    {\"vector\": [0.6, 0.7, 0.8, 0.9], \"nombre\": \"Escritorio\", \"categoria\": \"Muebles\"},\n",
    "    {\"vector\": [0.9, 0.8, 0.7, 0.6], \"nombre\": \"Silla\", \"categoria\": \"Muebles\"}\n",
    "]\n",
    "\n",
    "# Insertar datos en la tabla\n",
    "tabla.add(items)\n",
    "\n",
    "# Verificar los datos insertados\n",
    "df = tabla.to_pandas()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PMTgGIZbP4V6"
   },
   "source": [
    "**Task 3: Actualización de vectores y filtrado**\n",
    "\n",
    "Instrucciones:\n",
    "1. Crea una tabla utilizando un DataFrame de Pandas con las siguientes columnas:\n",
    "- id (Entero).\n",
    "- vector (Lista de tres números flotantes)\n",
    "2. Actualiza el vector de la fila donde id=3 a [10.0, 11.0, 10.0]\n",
    "3. Filtra la tabla para mostrar solo las filas donde al menos un valor del vector sea mayor a 9.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "gKkb7mmgRNWO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-05T17:49:01Z WARN  lance::dataset] No existing dataset at /usr/src/app/notebooks/data/ANN/pd_table.lance, it will be created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla 'pd_table' creada con éxito con el esquema:\n",
      "id: int64\n",
      "vector: fixed_size_list<item: float>[3]\n",
      "  child 0, item: float\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-05T17:49:01Z WARN  lance_core::utils::tokio] Number of CPUs is less than or equal to the number of IO core reservations. This is not a supported configuration. using 1 CPU for compute intensive tasks.\n",
      "[2024-12-05T17:49:01Z WARN  lance_core::utils::tokio] Number of CPUs is less than or equal to the number of IO core reservations. This is not a supported configuration. using 1 CPU for compute intensive tasks.\n",
      "[2024-12-05T17:49:01Z WARN  lance_core::utils::tokio] Number of CPUs is less than or equal to the number of IO core reservations. This is not a supported configuration. using 1 CPU for compute intensive tasks.\n",
      "[2024-12-05T17:49:01Z WARN  lance_core::utils::tokio] Number of CPUs is less than or equal to the number of IO core reservations. This is not a supported configuration. using 1 CPU for compute intensive tasks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id              vector\n",
      "2   4    [1.0, 11.0, 1.2]\n",
      "3   5   [1.3, 14.0, 15.0]\n",
      "4   3  [10.0, 11.0, 10.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-05T17:49:01Z WARN  lance_core::utils::tokio] Number of CPUs is less than or equal to the number of IO core reservations. This is not a supported configuration. using 1 CPU for compute intensive tasks.\n",
      "[2024-12-05T17:49:01Z WARN  lance_core::utils::tokio] Number of CPUs is less than or equal to the number of IO core reservations. This is not a supported configuration. using 1 CPU for compute intensive tasks.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import lancedb\n",
    "\n",
    "# Conectar o crear la base de datos\n",
    "uri = \"data/ANN\"  # Directorio donde se guardará la base de datos\n",
    "db = lancedb.connect(uri)\n",
    "\n",
    "# Crear un DataFrame con las columnas id y vector\n",
    "data = pd.DataFrame({\n",
    "    \"id\": [1, 2, 3, 4, 5],  # id como enteros\n",
    "    \"vector\": [\n",
    "        [1, 2, 3], \n",
    "        [4, 5, 6], \n",
    "        [7, 8, 9],\n",
    "        [1.0, 11, 1.2],\n",
    "        [1.3, 14, 15]\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Crear la tabla en LanceDB usando el DataFrame\n",
    "table_pd = db.create_table(\"pd_table\", data, exist_ok=True, mode=\"overwrite\")\n",
    "\n",
    "# Mostrar el esquema de la tabla para verificar que se creó correctamente\n",
    "print(f\"Tabla '{table_pd.name}' creada con éxito con el esquema:\")\n",
    "print(table_pd.schema)\n",
    "\n",
    "# Actualizar el vector donde id = 3\n",
    "table_pd.update(where=\"id == 3\", values={\"vector\": [10.0, 11.0, 10.0]})\n",
    "\n",
    "# Filtrar la tabla para mostrar solo las filas donde al menos un valor del vector sea mayor a 9.0\n",
    "filtered_df = table_pd.to_pandas()\n",
    "\n",
    "# Aplicar el filtro\n",
    "filtered_df = filtered_df[filtered_df['vector'].apply(lambda x: any(i > 9.0 for i in x))]\n",
    "\n",
    "# Mostrar los resultados filtrados\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rargPzZFP4nX"
   },
   "source": [
    "**Task 4: Embeddings multimodales y búsqueda combinada**\n",
    "\n",
    "Instrucciones:\n",
    "1. Crea una tabla con datos de texto e imágenes combinados. Incluye las siguientes columnas:\n",
    "- texto (Texto).\n",
    "- imagen (Nombre del archivo de imagen).\n",
    "- embedding_texto (Vector del texto generado con SentenceTransformer).\n",
    "- embedding_imagen (Vector de la imagen generado con ResNet18).\n",
    "2. Realiza una consulta para encontrar los elementos con un texto similar a \"La tecnología avanza rápido\" y una imagen visualmente similar a un color predominantemente azul.\n",
    "3. Muestra los resultados combinados ordenados por la menor distancia promedio entre ambos embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "YIY57gZHQgBv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base de datos configurada en: data/vectorial_db\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "336069ef453a49629e4673cde85daa89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0303b22196e94522be6ccfa78ecdfb9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d34d5288ff0242509845c25eefebf5b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c592452e0ac041ba9344f89f38fa5cee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e6635edb61542cd8c7b4dc5ebbe9e3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f45977fec640447287b3a98666e78085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27a41b2752ad4353ad641baa464a7bfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68d1f58191fa40dd8df8eb4217ec4ffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "831fe591dc1c4110a379379e375a9010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd8bc2ddfc964d9a80a68e0e8c2fc860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b73419f3b2054416a3d3fea78bff8316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:05<00:00, 8.22MB/s]\n",
      "[2024-12-05T17:51:09Z WARN  lance::dataset] No existing dataset at /usr/src/app/notebooks/data/vectorial_db/multimodal_embeddings.lance, it will be created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla 'multimodal_embeddings' creada con éxito.\n",
      "Resultados ordenados por menor distancia promedio:\n",
      "                                               texto  \\\n",
      "0           Viajar es una experiencia enriquecedora.   \n",
      "1                  Los gatos son mascotas populares.   \n",
      "2                        La tecnología avanza rápido   \n",
      "3              Las flores son coloridas y fragantes.   \n",
      "4  La inteligencia artificial está transformando ...   \n",
      "5                        El cielo es azul y hermoso.   \n",
      "\n",
      "                             imagen   distance  \n",
      "0  lancedb_embedded_explanation.png  34.785149  \n",
      "1                        ivf_pq.png  34.935299  \n",
      "2                      imagen_3.jpg  38.116432  \n",
      "3                      imagen_4.jpg  38.346001  \n",
      "4                      imagen_6.jpg  39.997059  \n",
      "5                      imagen_2.jpg  45.970905  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-05T17:51:09Z WARN  lance_core::utils::tokio] Number of CPUs is less than or equal to the number of IO core reservations. This is not a supported configuration. using 1 CPU for compute intensive tasks.\n",
      "[2024-12-05T17:51:09Z WARN  lance_core::utils::tokio] Number of CPUs is less than or equal to the number of IO core reservations. This is not a supported configuration. using 1 CPU for compute intensive tasks.\n"
     ]
    }
   ],
   "source": [
    "# Parte 1\n",
    "import lancedb\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from PIL import Image\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import pyarrow as pa\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Configurar LanceDB\n",
    "db_path = \"data/vectorial_db\"  # Ruta donde se almacenará la base de datos\n",
    "\n",
    "# Crear el directorio si no existe\n",
    "os.makedirs(db_path, exist_ok=True)\n",
    "\n",
    "# Conectar a LanceDB\n",
    "db = lancedb.connect(db_path)\n",
    "print(f\"Base de datos configurada en: {db_path}\")\n",
    "\n",
    "# Cargar modelo para embeddings de texto\n",
    "text_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Datos de texto de ejemplo\n",
    "text_data = [\n",
    "    \"El cielo es azul y hermoso.\",\n",
    "    \"Los gatos son mascotas populares.\",\n",
    "    \"La inteligencia artificial está transformando el mundo.\",\n",
    "    \"Las flores son coloridas y fragantes.\",\n",
    "    \"Viajar es una experiencia enriquecedora.\",\n",
    "    \"La tecnología avanza rápido\"\n",
    "]\n",
    "\n",
    "# Generar embeddings de texto\n",
    "text_embeddings = text_model.encode(text_data)\n",
    "text_embeddings = [embedding.astype(np.float32).tolist() for embedding in text_embeddings]  # Convertir a float32\n",
    "\n",
    "# Crear DataFrame con los datos y embeddings de texto\n",
    "df_text = pd.DataFrame({\n",
    "    \"texto\": text_data,\n",
    "    \"embedding_texto\": text_embeddings\n",
    "})\n",
    "\n",
    "# Configuración del modelo de imagen ResNet18\n",
    "image_model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "image_model.eval()\n",
    "\n",
    "# Configuración de la transformación de imágenes\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Ruta de la carpeta de imágenes\n",
    "image_dir = \"data/images\"\n",
    "\n",
    "# Procesar las imágenes y generar embeddings\n",
    "image_embeddings = []\n",
    "image_data = []\n",
    "\n",
    "for image_file in os.listdir(image_dir):\n",
    "    if image_file.endswith(\".jpg\") or image_file.endswith(\".png\"):\n",
    "        img_path = os.path.join(image_dir, image_file)\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img_tensor = image_transform(img).unsqueeze(0)\n",
    "\n",
    "        # Generar embedding de la imagen\n",
    "        with torch.no_grad():\n",
    "            embedding = image_model(img_tensor).squeeze().numpy().astype('float32')\n",
    "\n",
    "        image_data.append(image_file)  # Nombre de la imagen\n",
    "        image_embeddings.append(embedding.tolist())  # Embedding como lista\n",
    "\n",
    "# Crear DataFrame con los datos y embeddings de imagen\n",
    "df_images = pd.DataFrame({\n",
    "    \"imagen\": image_data,\n",
    "    \"embedding_imagen\": image_embeddings\n",
    "})\n",
    "\n",
    "# Crear DataFrame combinado de texto e imagen\n",
    "df_combined = pd.merge(df_text, df_images, left_index=True, right_index=True, how='outer')\n",
    "\n",
    "# Crear esquema Arrow con las columnas 'texto', 'imagen', 'embedding_texto', 'embedding_imagen'\n",
    "schema = pa.schema([\n",
    "    (\"texto\", pa.string()),  # Columna de texto\n",
    "    (\"imagen\", pa.string()),  # Columna de imagen\n",
    "    (\"embedding_texto\", pa.list_(pa.float32(), list_size=len(text_embeddings[0]))),  # Embedding de texto\n",
    "    (\"embedding_imagen\", pa.list_(pa.float32(), list_size=len(image_embeddings[0])))  # Embedding de imagen\n",
    "])\n",
    "\n",
    "# Convertir el DataFrame combinado en una tabla Arrow\n",
    "table_combined = pa.Table.from_pandas(df_combined, schema=schema)\n",
    "\n",
    "# Guardar la tabla combinada en LanceDB\n",
    "tabla_combined = db.create_table(\"multimodal_embeddings\", data=table_combined, mode=\"overwrite\")\n",
    "print(\"Tabla 'multimodal_embeddings' creada con éxito.\")\n",
    "\n",
    "# Parte 2: Consultas y cálculo de distancia promedio\n",
    "\n",
    "# 1. Consulta de texto: Similaridad con \"La tecnología avanza rápido\"\n",
    "query_text = \"La tecnología avanza rápido\"  # Texto de consulta\n",
    "query_text_embedding = text_model.encode([query_text])[0].astype(np.float32)  # Generar embedding\n",
    "\n",
    "# 2. Consulta de imagen: Similaridad con color predominantemente azul\n",
    "query_image = Image.new(\"RGB\", (224, 224), (50, 50, 255))  # Color RGB con predominancia azul\n",
    "query_image_tensor = image_transform(query_image).unsqueeze(0)\n",
    "\n",
    "# Generar embedding para la imagen de consulta\n",
    "with torch.no_grad():\n",
    "    query_image_embedding = image_model(query_image_tensor).squeeze().numpy().astype('float32')\n",
    "\n",
    "# Recuperar datos de la tabla para procesarlos\n",
    "results = tabla_combined.to_pandas()\n",
    "\n",
    "# Filtrar filas donde ambos embeddings no sean None\n",
    "results = results.dropna(subset=[\"embedding_texto\", \"embedding_imagen\"]).reset_index(drop=True)\n",
    "\n",
    "# Calcular distancia promedio entre embeddings\n",
    "def calculate_combined_distance(row):\n",
    "    text_distance = np.linalg.norm(np.array(row[\"embedding_texto\"]) - query_text_embedding)\n",
    "    image_distance = np.linalg.norm(np.array(row[\"embedding_imagen\"]) - query_image_embedding)\n",
    "    return (text_distance + image_distance) / 2\n",
    "\n",
    "# Aplicar cálculo de distancia\n",
    "results[\"distance\"] = results.apply(calculate_combined_distance, axis=1)\n",
    "\n",
    "# Ordenar por la menor distancia promedio\n",
    "results = results.sort_values(\"distance\").reset_index(drop=True)\n",
    "\n",
    "# Mostrar los resultados combinados\n",
    "print(\"Resultados ordenados por menor distancia promedio:\")\n",
    "print(results[[\"texto\", \"imagen\", \"distance\"]])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
